

<!doctype html>
<html prefix="og: http://ogp.me/ns#">
<head>
  <meta charset="utf-8">
  <title>awesome-spark: A curated list of awesome Apache Spark packages and resources.</title>
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta property="og:title" content="awesome-spark: A curated list of awesome Apache Spark packages and resources.">
  <link rel="icon" type="image/png" href="/public/Awesome64.png" />
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/bulma/0.8.2/css/bulma.min.css" />
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/tabulator/4.6.3/css/bulma/tabulator_bulma.min.css" />
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/select2/4.0.12/css/select2.min.css" />
  <style>
    .menu-label{ font-weight: bold;}
  </style>
</head>
<body>

<nav class="navbar has-shadow">
  <div class="container">
      <div class="navbar-brand">
          <a class="navbar-item" style="padding: 0px" href="/">
              <img src="/public/Awesome.png"
                style="max-height: 90px;"
               alt="Awesome Collections">
          </a>

      </div>
      <div class="navbar-end">
      <p class="control navbar-item">
        <span class="select">
        <select id="sel-search"
          class="form-control"
          placeholder="Search"
          >
          <option value=""></option>
        </select>
        </span>
        </p>
          <div class="navbar-item is-hoverable">
              <a href="/index.html">
              Home
              </a>
          </div>
          <div class="navbar-item is-hoverable">
              <a href="/about.html">
              About
              </a>
          </div>
      </div>
  </div>
</nav>
<h2 class="title">awesome-spark: A curated list of awesome Apache Spark packages and resources.</h2>

<section>




<div class="columns">

<div class="field has-addons has-addons-centered column">
  <p class="control">
    <span class="select">
      <select id="filter-field">
        <option></option>
        <option value="Name">Name</option>
        <option value="Description" selected>Description</option>
        <option value="Category">Category</option>
        <option value="Stars">Stars</option>
        <option value="Forks">Forks</option>
        <option value="Open">️Open</option>
        <option value="Closed">️Closed</option>
        <option value="Created">Created</option>
        <option value="Pushed">Pushed</option>
        <option value="Size">Size</option>
        <option value="Language">Language</option>
        <option value="Archived">Archived</option>
        <option value="License">License</option>

      </select>
    </span>
  </p>
  <p class="control">
    <span class="select">
    <select id="filter-type">
      <option value="like">like</option>
      <option value="=">=</option>
      <option value="<">&lt;</option>
      <option value="<=">&lt;=</option>
      <option value=">">></option>
      <option value=">=">>=</option>
      <option value="!=">!=</option>
    </select>

    </span>
  </p>
  <p class="control">
    <input class="input" id="filter-value" type="text" placeholder="Search Table">
  </p>
</div>
<div class="column">
    <button id="filter-clear" class="button is-info">Clear Filter</button>
  <button id='btn-group' class="button is-primary" >Group</button>
  <button id="btn-ungroup" class="button is-primary" >Ungroup</button>
</div>
</div>

<table id="awesome-table">
  <thead>
      <tr>
        <th>Name</th>
        <th>Description</th>
        <th>Created</th>
        <th>Pushed</th>
        <th>Stars</th>
        <th>Forks</th>
        <th>️Open</th>
        <th>️Closed</th>
        <th>Size</th>
        <th>Language</th>
        <th>Archived</th>
        <th>License</th>
        <th>Category</th>
      </tr>
  </thead>
  <tbody>

  <tr><td><a href="https://github.com/hail-is/hail" target="_blank">hail</a></td><td>Scalable genomic data analysis.
&lt;img src=&#34;https://img.shields.io/github/last-commit/hail-is/hail.svg&#34;&gt; - Genetic analysis framework.</td><td>2015-10-27</td><td>2020-05-06</td><td>618</td><td>164</td><td>6</td><td>1903</td><td>85251</td><td>Scala</td><td>false</td><td>MIT License</td><td>Bioinformatics</td></tr><tr><td><a href="https://github.com/awesome-spark/spark-gotchas" target="_blank">spark-gotchas</a></td><td>Spark Gotchas. A subjective compilation of the Apache Spark tips and tricks
Subjective compilation of tips, tricks and common programming mistakes.</td><td>2016-06-02</td><td>2017-06-06</td><td>276</td><td>59</td><td>5</td><td>8</td><td>193</td><td></td><td>true</td><td>Other</td><td>Books</td></tr><tr><td><a href="https://github.com/sequenceiq/docker-spark" target="_blank">docker-spark</a></td><td>
Yarn images from [SequenceIQ](http://www.sequenceiq.com/).</td><td>2014-07-11</td><td>2020-02-12</td><td>771</td><td>301</td><td>22</td><td>25</td><td>96</td><td>Shell</td><td>false</td><td>Apache License 2.0</td><td>Docker Images</td></tr><tr><td><a href="https://github.com/DataSystemsLab/GeoSpark" target="_blank">GeoSpark</a></td><td>A Cluster Computing System for Processing Large-Scale Spatial Data
&lt;img src=&#34;https://img.shields.io/github/last-commit/Sarwat/GeoSpark.svg&#34;&gt; - Cluster computing system for processing large-scale spatial data.</td><td>2015-04-24</td><td>2020-05-04</td><td>661</td><td>333</td><td>102</td><td>144</td><td>316680</td><td>Java</td><td>false</td><td>Other</td><td>GIS</td></tr><tr><td><a href="https://github.com/harsha2010/magellan" target="_blank">magellan</a></td><td>Geo Spatial Data Analytics on Spark
&lt;img src=&#34;https://img.shields.io/github/last-commit/harsha2010/magellan.svg&#34;&gt; - Geospatial analytics using Spark.</td><td>2015-06-01</td><td>2019-10-05</td><td>483</td><td>142</td><td>66</td><td>72</td><td>13641</td><td>Scala</td><td>false</td><td>Apache License 2.0</td><td>GIS</td></tr><tr><td><a href="https://github.com/graphframes/graphframes" target="_blank">graphframes</a></td><td>
&lt;img src=&#34;https://img.shields.io/github/last-commit/graphframes/graphframes.svg&#34;&gt; - Data frame based graph API.</td><td>2016-01-20</td><td>2020-04-21</td><td>641</td><td>182</td><td>116</td><td>73</td><td>1600</td><td>Scala</td><td>false</td><td>Apache License 2.0</td><td>Graph Processing</td></tr><tr><td><a href="https://github.com/neo4j-contrib/neo4j-mazerunner" target="_blank">neo4j-mazerunner</a></td><td>Mazerunner extends a Neo4j graph database to run scheduled big data graph compute algorithms at scale with HDFS and Apache Spark.
&lt;img src=&#34;https://img.shields.io/github/last-commit/neo4j-contrib/neo4j-mazerunner.svg&#34;&gt; - Graph analytics platform on top of Neo4j and GraphX.</td><td>2014-10-28</td><td>2019-12-02</td><td>369</td><td>114</td><td>26</td><td>13</td><td>311322</td><td>Java</td><td>false</td><td>Apache License 2.0</td><td>Graph Processing</td></tr><tr><td><a href="https://github.com/blaze/blaze" target="_blank">blaze</a></td><td>NumPy and Pandas interface to Big Data
&lt;img src=&#34;https://img.shields.io/github/last-commit/blaze/blaze.svg&#34;&gt; - Interface for querying larger than memory datasets using Pandas-like syntax. It supports both Spark `DataFrames` and `RDDs`.</td><td>2012-10-26</td><td>2020-02-01</td><td>2854</td><td>371</td><td>250</td><td>499</td><td>22938</td><td>Python</td><td>false</td><td>Other</td><td>Interfaces</td></tr><tr><td><a href="https://github.com/microsoft/Mobius" target="_blank">Mobius</a></td><td>C# and F# language binding and extensions to Apache Spark
&lt;img src=&#34;https://img.shields.io/github/last-commit/Microsoft/Mobius.svg&#34;&gt; - C# bindings.</td><td>2015-10-27</td><td>2019-11-01</td><td>925</td><td>209</td><td>51</td><td>141</td><td>6791</td><td>C#</td><td>false</td><td>MIT License</td><td>Language Bindings</td></tr><tr><td><a href="https://github.com/sparklyr/sparklyr" target="_blank">sparklyr</a></td><td>R interface for Apache Spark
&lt;img src=&#34;https://img.shields.io/github/last-commit/rstudio/sparklyr.svg&#34;&gt; - An alternative R backend, using [`dplyr`](https://github.com/hadley/dplyr).</td><td>2016-05-20</td><td>2020-05-06</td><td>733</td><td>270</td><td>485</td><td>1075</td><td>72014</td><td>R</td><td>false</td><td>Apache License 2.0</td><td>Language Bindings</td></tr><tr><td><a href="https://github.com/sorenmacbeth/flambo" target="_blank">flambo</a></td><td>A Clojure DSL for Apache Spark
&lt;img src=&#34;https://img.shields.io/github/last-commit/yieldbot/flambo.svg&#34;&gt; - Clojure DSL.</td><td>2014-01-07</td><td>2018-07-31</td><td>604</td><td>90</td><td>11</td><td>67</td><td>729</td><td>Clojure</td><td>false</td><td>Eclipse Public License 1.0</td><td>Language Bindings</td></tr><tr><td><a href="https://github.com/tweag/sparkle" target="_blank">sparkle</a></td><td>Haskell on Apache Spark.
&lt;img src=&#34;https://img.shields.io/github/last-commit/tweag/sparkle.svg&#34;&gt; - Haskell on Apache Spark.</td><td>2015-11-09</td><td>2019-06-10</td><td>401</td><td>28</td><td>22</td><td>48</td><td>625</td><td>Haskell</td><td>false</td><td>Other</td><td>Language Bindings</td></tr><tr><td><a href="https://github.com/intel-analytics/BigDL" target="_blank">BigDL</a></td><td>BigDL: Distributed Deep Learning Library for Apache Spark
&lt;img src=&#34;https://img.shields.io/github/last-commit/intel-analytics/BigDL.svg&#34;&gt; - Distributed Deep Learning library.</td><td>2016-08-29</td><td>2020-04-15</td><td>3302</td><td>848</td><td>136</td><td>702</td><td>24823</td><td>Scala</td><td>false</td><td>Apache License 2.0</td><td>Machine Learning Extension</td></tr><tr><td><a href="https://github.com/combust/mleap" target="_blank">mleap</a></td><td>MLeap: Deploy Spark Pipelines to Production
&lt;img src=&#34;https://img.shields.io/github/last-commit/combust/mleap.svg&#34;&gt; - Execution engine and serialization format which supports deployment of `o.a.s.ml` models without dependency on `SparkSession`.</td><td>2016-08-23</td><td>2020-05-05</td><td>1047</td><td>246</td><td>99</td><td>278</td><td>2726</td><td>Scala</td><td>false</td><td>Apache License 2.0</td><td>Machine Learning Extension</td></tr><tr><td><a href="https://github.com/databricks/spark-sklearn" target="_blank">spark-sklearn</a></td><td>(Deprecated) Scikit-learn integration package for Apache Spark
&lt;img src=&#34;https://img.shields.io/github/last-commit/databricks/spark-sklearn.svg&#34;&gt; - Scikit-learn integration with distributed model training.</td><td>2015-09-02</td><td>2019-12-03</td><td>1039</td><td>236</td><td>14</td><td>35</td><td>801</td><td>Python</td><td>true</td><td>Apache License 2.0</td><td>Machine Learning Extension</td></tr><tr><td><a href="https://github.com/h2oai/sparkling-water" target="_blank">sparkling-water</a></td><td>Sparkling Water provides H2O functionality inside Spark cluster
&lt;img src=&#34;https://img.shields.io/github/last-commit/h2oai/sparkling-water.svg&#34;&gt; -  [H2O](http://www.h2o.ai/) interoperability layer.</td><td>2014-10-13</td><td>2020-05-05</td><td>845</td><td>354</td><td>0</td><td>214</td><td>35138</td><td>Scala</td><td>false</td><td>Apache License 2.0</td><td>Machine Learning Extension</td></tr><tr><td><a href="https://github.com/cerndb/dist-keras" target="_blank">dist-keras</a></td><td>Distributed Deep Learning, with a focus on distributed training, using Keras and Apache Spark.
&lt;img src=&#34;https://img.shields.io/github/last-commit/cerndb/dist-keras.svg&#34;&gt; - Distributed deep learning framework with PySpark and Keras.</td><td>2016-07-25</td><td>2018-07-25</td><td>611</td><td>168</td><td>31</td><td>42</td><td>57240</td><td>Python</td><td>true</td><td>GNU General Public License v3.0</td><td>Machine Learning Extension</td></tr><tr><td><a href="https://github.com/irvingc/dbscan-on-spark" target="_blank">dbscan-on-spark</a></td><td>An implementation of DBSCAN runing on top of Apache Spark
&lt;img src=&#34;https://img.shields.io/github/last-commit/irvingc/dbscan-on-spark.svg&#34;&gt; - An Implementation of the DBSCAN clustering algorithm on top of Apache Spark by [irvingc](https://github.com/irvingc) and based on the paper from He, Yaobin, et al. [MR-DBSCAN: a scalable MapReduce-based DBSCAN algorithm for heavily skewed data](https://www.researchgate.net/profile/Yaobin_He/publication/260523383_MR-DBSCAN_a_scalable_MapReduce-based_DBSCAN_algorithm_for_heavily_skewed_data/links/0046353a1763ee2bdf000000.pdf).</td><td>2015-03-15</td><td>2018-01-10</td><td>146</td><td>49</td><td>9</td><td>4</td><td>114</td><td>Scala</td><td>false</td><td>Apache License 2.0</td><td>Machine Learning Extension</td></tr><tr><td><a href="https://github.com/jpmml/jpmml-evaluator-spark" target="_blank">jpmml-evaluator-spark</a></td><td>PMML evaluator library for the Apache Spark cluster computing system (http://spark.apache.org/)
&lt;img src=&#34;https://img.shields.io/github/last-commit/jpmml/jpmml-spark.svg&#34;&gt; - PMML transformer library for Spark ML.</td><td>2015-11-29</td><td>2019-01-16</td><td>86</td><td>39</td><td>8</td><td>27</td><td>93</td><td>Java</td><td>false</td><td>GNU Affero General Public License v3.0</td><td>Machine Learning Extension</td></tr><tr><td><a href="https://github.com/Clustering4Ever/Clustering4Ever" target="_blank">Clustering4Ever</a></td><td>C4E, a Scala or Spark library for local and distributed Clustering.
&lt;img src=&#34;https://img.shields.io/github/last-commit/Clustering4Ever/Clustering4Ever.svg&#34;&gt; Scala and Spark API to benchmark and analyse clustering algorithms on any vectorization you can generate</td><td>2018-03-26</td><td>2020-05-03</td><td>82</td><td>8</td><td>0</td><td>0</td><td>1520</td><td>Scala</td><td>false</td><td>Apache License 2.0</td><td>Machine Learning Extension</td></tr><tr><td><a href="https://github.com/spark-jobserver/spark-jobserver" target="_blank">spark-jobserver</a></td><td>REST job server for Apache Spark
&lt;img src=&#34;https://img.shields.io/github/last-commit/spark-jobserver/spark-jobserver.svg&#34;&gt; - Simple Spark as a Service which supports objects sharing using so called named objects. JVM only.</td><td>2014-08-21</td><td>2020-05-05</td><td>2532</td><td>961</td><td>137</td><td>643</td><td>4831</td><td>Scala</td><td>false</td><td>Other</td><td>Middleware</td></tr><tr><td><a href="https://github.com/cloudera/livy" target="_blank">livy</a></td><td>Livy is an open source REST interface for interacting with Apache Spark from anywhere
&lt;img src=&#34;https://img.shields.io/github/last-commit/cloudera/livy.svg&#34;&gt; - REST server with extensive language support (Python, R, Scala), ability to maintain interactive sessions and object sharing.</td><td>2015-11-17</td><td>2020-02-11</td><td>913</td><td>307</td><td>0</td><td>0</td><td>2269</td><td>Scala</td><td>false</td><td></td><td>Middleware</td></tr><tr><td><a href="https://github.com/apache/incubator-toree" target="_blank">incubator-toree</a></td><td>Mirror of Apache Toree (Incubating)
&lt;img src=&#34;https://img.shields.io/github/last-commit/apache/incubator-toree.svg&#34;&gt; - IPython protocol based middleware for interactive applications.</td><td>2016-01-07</td><td>2020-03-16</td><td>645</td><td>209</td><td>0</td><td>0</td><td>11097</td><td>Scala</td><td>false</td><td>Apache License 2.0</td><td>Middleware</td></tr><tr><td><a href="https://github.com/Hydrospheredata/mist" target="_blank">mist</a></td><td>Serverless proxy for Spark cluster
&lt;img src=&#34;https://img.shields.io/github/last-commit/Hydrospheredata/mist.svg&#34;&gt; - Service for exposing Spark analytical jobs and machine learning models as realtime, batch or reactive web services.</td><td>2016-01-15</td><td>2019-10-07</td><td>286</td><td>63</td><td>28</td><td>150</td><td>10461</td><td>Scala</td><td>false</td><td>Apache License 2.0</td><td>Middleware</td></tr><tr><td><a href="https://github.com/JohnSnowLabs/spark-nlp" target="_blank">spark-nlp</a></td><td>State of the Art Natural Language Processing
&lt;img src=&#34;https://img.shields.io/github/last-commit/JohnSnowLabs/spark-nlp.svg&#34;&gt; - Natural language processing library built on top of Apache Spark ML. </td><td>2017-09-24</td><td>2020-05-05</td><td>1146</td><td>268</td><td>42</td><td>222</td><td>200244</td><td>Scala</td><td>false</td><td>Apache License 2.0</td><td>Natural Language Processing</td></tr><tr><td><a href="https://github.com/databricks/spark-corenlp" target="_blank">spark-corenlp</a></td><td>Stanford CoreNLP wrapper for Apache Spark
&lt;img src=&#34;https://img.shields.io/github/last-commit/databricks/spark-corenlp.svg&#34;&gt; - DataFrame wrapper for [Stanford CoreNLP](https://stanfordnlp.github.io/CoreNLP/).</td><td>2015-08-21</td><td>2018-11-15</td><td>409</td><td>118</td><td>16</td><td>13</td><td>61</td><td>Scala</td><td>false</td><td>GNU General Public License v3.0</td><td>Natural Language Processing</td></tr><tr><td><a href="https://github.com/spark-notebook/spark-notebook" target="_blank">spark-notebook</a></td><td>Interactive and Reactive Data Science using Scala and Spark.
&lt;img src=&#34;https://img.shields.io/github/last-commit/spark-notebook/spark-notebook.svg&#34;&gt; - Scalable and stable Scala and Spark focused notebook bridging the gap between JVM and Data Scientists (incl. extendable, typesafe and reactive charts).</td><td>2014-09-05</td><td>2019-06-27</td><td>2923</td><td>630</td><td>205</td><td>306</td><td>16535</td><td>JavaScript</td><td>false</td><td>Apache License 2.0</td><td>Notebooks and IDEs</td></tr><tr><td><a href="https://github.com/jupyter-incubator/sparkmagic" target="_blank">sparkmagic</a></td><td>Jupyter magics and kernels for working with remote Spark clusters
&lt;img src=&#34;https://img.shields.io/github/last-commit/jupyter-incubator/sparkmagic.svg&#34;&gt; - [Jupyter](https://jupyter.org/) magics and kernels for working with remote Spark clusters, for interactively working with remote Spark clusters through [Livy](https://github.com/cloudera/livy), in Jupyter notebooks.</td><td>2015-09-21</td><td>2020-04-17</td><td>822</td><td>292</td><td>102</td><td>218</td><td>1852</td><td>Python</td><td>false</td><td>Other</td><td>Notebooks and IDEs</td></tr><tr><td><a href="https://github.com/OryxProject/oryx" target="_blank">oryx</a></td><td>Oryx 2: Lambda architecture on Apache Spark, Apache Kafka for real-time large scale machine learning
[Lambda architecture](http://lambda-architecture.net/) platform built on Apache Spark and [Apache Kafka](http://kafka.apache.org/) with specialization for real-time large scale machine learning.</td><td>2014-07-25</td><td>2020-03-17</td><td>1697</td><td>404</td><td>4</td><td>201</td><td>7345</td><td>Java</td><td>false</td><td>Apache License 2.0</td><td>Projects Using Spark</td></tr><tr><td><a href="https://github.com/linkedin/photon-ml" target="_blank">photon-ml</a></td><td>A scalable machine learning library on Apache Spark
A machine learning library supporting classical Generalized Mixed Model and Generalized Additive Mixed Effect Model.</td><td>2016-02-03</td><td>2020-05-05</td><td>731</td><td>185</td><td>19</td><td>98</td><td>102166</td><td>Scala</td><td>false</td><td>Other</td><td>Projects Using Spark</td></tr><tr><td><a href="https://github.com/Stratio/crossdata" target="_blank">crossdata</a></td><td>DISCONTINUED - Easy access to big things. Library for Apache Spark extending and improving its capabilities
Data integration platform with extended DataSource API and multi-user environment.</td><td>2014-02-06</td><td>2019-11-20</td><td>167</td><td>54</td><td>1</td><td>84</td><td>30744</td><td>Scala</td><td>true</td><td>Apache License 2.0</td><td>Projects Using Spark</td></tr><tr><td><a href="https://github.com/datastax/spark-cassandra-connector" target="_blank">spark-cassandra-connector</a></td><td>DataStax Spark Cassandra Connector
&lt;img src=&#34;https://img.shields.io/github/last-commit/datastax/spark-cassandra-connector.svg&#34;&gt; - Cassandra support including data source and API and support for arbitrary queries.</td><td>2014-06-27</td><td>2020-05-05</td><td>1697</td><td>815</td><td>1</td><td>399</td><td>13175</td><td>Scala</td><td>false</td><td>Apache License 2.0</td><td>SQL Data Sources</td></tr><tr><td><a href="https://github.com/databricks/spark-csv" target="_blank">spark-csv</a></td><td>CSV Data Source for Apache Spark 1.x
&lt;img src=&#34;https://img.shields.io/github/last-commit/databricks/spark-csv.svg&#34;&gt; - CSV reader and writer (obsolete since Spark 2.0 [[SPARK-12833]](https://issues.apache.org/jira/browse/SPARK-12833)). </td><td>2014-12-03</td><td>2018-12-13</td><td>1010</td><td>443</td><td>0</td><td>0</td><td>438</td><td>Scala</td><td>false</td><td>Apache License 2.0</td><td>SQL Data Sources</td></tr><tr><td><a href="https://github.com/mongodb/mongo-spark" target="_blank">mongo-spark</a></td><td>The MongoDB Spark Connector
&lt;img src=&#34;https://img.shields.io/github/last-commit/mongodb/mongo-spark.svg&#34;&gt; - Official MongoDB connector.</td><td>2015-05-20</td><td>2019-11-28</td><td>539</td><td>233</td><td>0</td><td>0</td><td>2071</td><td>Scala</td><td>false</td><td>Other</td><td>SQL Data Sources</td></tr><tr><td><a href="https://github.com/databricks/spark-avro" target="_blank">spark-avro</a></td><td>Avro Data Source for Apache Spark
&lt;img src=&#34;https://img.shields.io/github/last-commit/databricks/spark-avro.svg&#34;&gt; - [Apache Avro](https://avro.apache.org/) reader and writer (obselete since Spark 2.4 [[SPARK-24768]](https://issues.apache.org/jira/browse/SPARK-24768)).</td><td>2014-09-30</td><td>2018-12-19</td><td>535</td><td>315</td><td>64</td><td>103</td><td>405</td><td>Scala</td><td>true</td><td>Apache License 2.0</td><td>SQL Data Sources</td></tr><tr><td><a href="https://github.com/databricks/spark-xml" target="_blank">spark-xml</a></td><td>XML data source for Spark SQL and DataFrames
&lt;img src=&#34;https://img.shields.io/github/last-commit/databricks/spark-xml.svg&#34;&gt; - XML parser and writer.</td><td>2015-11-26</td><td>2020-04-30</td><td>296</td><td>162</td><td>17</td><td>255</td><td>726</td><td>Scala</td><td>false</td><td>Apache License 2.0</td><td>SQL Data Sources</td></tr><tr><td><a href="https://github.com/basho/spark-riak-connector" target="_blank">spark-riak-connector</a></td><td>The official Riak Spark Connector for Apache Spark with Riak TS and Riak KV
&lt;img src=&#34;https://img.shields.io/github/last-commit/basho/spark-riak-connector.svg&#34;&gt; - Riak TS &amp; Riak KV connector.</td><td>2015-05-07</td><td>2017-03-17</td><td>45</td><td>30</td><td>4</td><td>8</td><td>5196</td><td>Scala</td><td>false</td><td>Apache License 2.0</td><td>SQL Data Sources</td></tr><tr><td><a href="https://github.com/orientechnologies/spark-orientdb" target="_blank">spark-orientdb</a></td><td>Apache Spark datasource for OrientDB
&lt;img src=&#34;https://img.shields.io/github/last-commit/orientechnologies/spark-orientdb.svg&#34;&gt; - Official OrientDB connector.</td><td>2016-10-31</td><td>2019-01-28</td><td>16</td><td>7</td><td>8</td><td>7</td><td>142</td><td>Scala</td><td>false</td><td>Other</td><td>SQL Data Sources</td></tr><tr><td><a href="https://github.com/holdenk/spark-testing-base" target="_blank">spark-testing-base</a></td><td>Base classes to use when writing tests with Spark
&lt;img src=&#34;https://img.shields.io/github/last-commit/holdenk/spark-testing-base.svg&#34;&gt; - Collection of base test classes.</td><td>2015-01-30</td><td>2020-04-07</td><td>1115</td><td>310</td><td>80</td><td>97</td><td>815</td><td>Scala</td><td>false</td><td>Apache License 2.0</td><td>Testing</td></tr><tr><td><a href="https://github.com/awslabs/deequ" target="_blank">deequ</a></td><td>Deequ is a library built on top of Apache Spark for defining &#34;unit tests for data&#34;, which measure data quality in large datasets.
&lt;img src=&#34;https://img.shields.io/github/last-commit/awslabs/deequ.svg&#34;&gt; - Deequ is a library built on top of Apache Spark for defining &#34;unit tests for data&#34;, which measure data quality in large datasets.</td><td>2018-08-07</td><td>2020-05-05</td><td>804</td><td>142</td><td>39</td><td>101</td><td>72408</td><td>Scala</td><td>false</td><td>Apache License 2.0</td><td>Testing</td></tr><tr><td><a href="https://github.com/MrPowers/spark-fast-tests" target="_blank">spark-fast-tests</a></td><td>Apache Spark testing helpers (dependency free &amp; works with Scalatest, uTest, and MUnit)
&lt;img src=&#34;https://img.shields.io/github/last-commit/MrPowers/spark-fast-tests.svg&#34;&gt; - A lightweight and fast testing framework.</td><td>2017-04-06</td><td>2020-04-07</td><td>183</td><td>33</td><td>25</td><td>19</td><td>607</td><td>Scala</td><td>false</td><td>MIT License</td><td>Testing</td></tr><tr><td><a href="https://github.com/sryza/spark-timeseries" target="_blank">spark-timeseries</a></td><td>A library for time series analysis on Apache Spark
&lt;img src=&#34;https://img.shields.io/github/last-commit/cloudera/spark-timeseries.svg&#34;&gt; - Scala / Java / Python library for interacting with time series data on Apache Spark.</td><td>2015-03-11</td><td>2018-02-01</td><td>1104</td><td>417</td><td>75</td><td>33</td><td>1983</td><td>Scala</td><td>false</td><td>Apache License 2.0</td><td>Time Series Analytics</td></tr><tr><td><a href="https://github.com/twosigma/flint" target="_blank">flint</a></td><td>A Time Series Library for Apache Spark
&lt;img src=&#34;https://img.shields.io/github/last-commit/twosigma/flint.svg&#34;&gt; - A time series library for Apache Spark.</td><td>2016-10-19</td><td>2019-10-19</td><td>789</td><td>168</td><td>33</td><td>19</td><td>1503</td><td>Scala</td><td>false</td><td>Apache License 2.0</td><td>Time Series Analytics</td></tr><tr><td><a href="https://github.com/nchammas/flintrock" target="_blank">flintrock</a></td><td>A command-line tool for launching Apache Spark clusters.
&lt;img src=&#34;https://img.shields.io/github/last-commit/nchammas/flintrock.svg&#34;&gt; - A command-line tool for launching Spark clusters on EC2.</td><td>2015-06-04</td><td>2020-05-06</td><td>514</td><td>97</td><td>34</td><td>141</td><td>689</td><td>Python</td><td>false</td><td>Other</td><td>Utilities</td></tr><tr><td><a href="https://github.com/tubular/sparkly" target="_blank">sparkly</a></td><td>Helpers &amp; syntactic sugar for PySpark. 
&lt;img src=&#34;https://img.shields.io/github/last-commit/Tubular/sparkly.svg&#34;&gt; - Helpers &amp; syntactic sugar for PySpark.</td><td>2016-10-07</td><td>2019-09-11</td><td>41</td><td>3</td><td>2</td><td>7</td><td>1500</td><td>Python</td><td>false</td><td>Apache License 2.0</td><td>Utilities</td></tr><tr><td><a href="https://github.com/willb/silex" target="_blank">silex</a></td><td>something to help you spark
&lt;img src=&#34;https://img.shields.io/github/last-commit/willb/silex.svg&#34;&gt; - Collection of tools varying from ML extensions to additional RDD methods.</td><td>2016-10-05</td><td>2017-07-05</td><td>17</td><td>0</td><td>0</td><td>0</td><td>1511</td><td>Scala</td><td>false</td><td>Apache License 2.0</td><td>Utilities</td></tr><tr><td><a href="https://github.com/archivesunleashed/aut" target="_blank">aut</a></td><td>      The Archives Unleashed Toolkit is an open-source toolkit for analyzing web archives.
&lt;img src=&#34;https://img.shields.io/github/last-commit/archivesunleashed/aut.svg&#34;&gt; -  Open-source toolkit for analyzing web archives.</td><td>2017-07-06</td><td>2020-05-05</td><td>89</td><td>24</td><td>25</td><td>207</td><td>39810</td><td>Scala</td><td>false</td><td>Apache License 2.0</td><td>Web Archives</td></tr>
  </tbody>
</table>
<script src="https://cdnjs.cloudflare.com/ajax/libs/tabulator/4.6.3/js/tabulator.min.js" integrity="sha256-iPjRCZa7o9UTQu2PxYlkbw20wAdnOShjVhpOXuE4LsU=" crossorigin="anonymous"></script>
<script src="/public/tabulize.js"></script>

</section>

<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha256-9/aliU8dGd2tb6OSsuzixeV4y/faTqgFtohetphbbj0=" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/select2/4.0.12/js/select2.min.js" integrity="sha256-wfVTTtJ2oeqlexBsfa3MmUoB77wDNRPqT1Q1WA2MMn4=" crossorigin="anonymous"></script>

<script>
$(document).ready(function() {
  $.getJSON('/indexLinks.json')
    .then(function(data) {
      $('#sel-search').select2({
        width: '200px',
        placeholder: "Search",
        data: data.results})
    })
    .catch(err => console.log(err));

  $('#sel-search').on('change', function(e){
    let lnk = e.target.value
    console.log(lnk)
    window.location = lnk
  });
});
</script>
</body>
</html>
